{
    "collab_server" : "",
    "contents" : "#' Obtains logistic fits for presence/absence and fitted probabilities of a zero occurring.\n#'\n#' This function is used to derive weights for feature-wise compositional estimates. Our (default)\n#' intention is to derive these based on average occurrences across the dataset, as just a function\n#' of sample depth, and not with particular relevance to groups.\n#' @param mat count matrix\n#' @param hdesign design matrix for the logistic; the default is usually sufficient.\n#' @param thresh True if numerically one/zero probability occurrences must be thresholded\n#' @param thresh.val if thresh is true, the numerically one/zero probability occurrences is thresholded\n#'        to this value\n#' @return A list with components:\n#'          \\itemize{\n#'          \\item{pi0.fit -  list with feature-wise glm.fit objects}\n#'          \\item{pi0 - matrix with fitted probabilities}\n#'          }\n#'\n#' @export\ngetHurdle <- function(mat, hdesign=model.matrix( ~-1+log(colSums(mat)) ),\n                      thresh=F, thresh.val=1e-8, ... ){\n  require(matrixStats)\n\n  pi0.fit <- apply(mat, 1, function(x) glm.fit( hdesign, c(1*(x==0)), family=binomial() ) )\n  pi0 <- t(sapply( pi0.fit, function(x) x$fitted.values  ))\n  if(thresh){\n    pi0[pi0>1-thresh.val] <- 1-thresh.val\n    pi0[pi0<thresh.val] <- thresh.val\n  }\n  list(\"pi0.fit\"=pi0.fit, \"pi0\"=pi0)\n}\n\n#' Obtain variances of logged counts.\n#'\n#'@param mat count matrix; rows are features and columns are samples.\n#'@param design model matrix for the count matrix\n#'@param plot if the mean-variance trend function (the same as that of voom) needs to be plot.\n#'@param ebs2 if regularization of variances needs to be performed.\n#'@param smoothed TRUE if all the variance estimates must be based on the mean-variance trend function.\n#'@return a vector with variance estimates for logged feature-wise counts.\n#'\n#'@export\ngets2 <- function(mat, design=model.matrix(mat[1,]~1), plot=F, ebs2=T, smoothed=F, ...){\n\n  require(matrixStats)\n  require(locfit)\n  require(limma)\n\n  p <- nrow(mat)\n  nzrows <- rowSums(mat)>0\n  mat <- mat[nzrows,]\n\n  tjs <- colSums(mat)\n  tjs <- tjs/exp(mean(log(tjs)))\n\n  design <- cbind( design, log(tjs) )\n  mat <- log(mat)\n  mat[!is.finite(mat)] <- NA\n  fit <- lmFit( mat, design  )\n  s <- fit$sigma\n  s[s==0] <- NA\n  mu <- rowMeans( mat, na.rm=T )\n\n  sqrt.s <- sqrt(s)\n  l <- locfit(sqrt.s~mu, family=\"gamma\")\n\n  if(plot){\n    plot( mu, sqrt.s, pch=16, cex=.25 )\n    lines(l, col='red')\n  }\n\n  k <- predict(l, mu)^4\n  if(smoothed){\n    s2 <- k\n  } else {\n    s2 <- s^2\n    s2[is.na(s2)] <- k[is.na(s2)]\n    if(ebs2){\n      s2 <- limma::squeezeVar(s2, df = max(c(1, fit$df.residual), na.rm=T) )$var.post\n    }\n  }\n  s2.tmp <- c(matrix(NA, nrow=p, ncol=1))\n  s2.tmp[nzrows] <- s2\n  s2.tmp\n}\n\n#' Marginal weight computations for wrench estimators.\n#' @param res result structure of \\code{wrench}\n#' @param z.adj TRUE if the result structure was generated with \\code{wrench} with \\code{z.adj} set to TRUE.\n#' @export\ngetMargWeights <- function( res, z.adj, ...  ){\n  with(res$others, {\n    s2theta <- design %*% s2thetag\n    tmp <- exp( sweep( replicate( nrow(design), s2 ), 2, s2theta, \"+\" ))-1\n    if(!z.adj){\n      W<-1/( (1-pi0)*( pi0 + tmp ) )\n      W[!is.finite(W)] <- NA\n    } else {\n      W<-(1-pi0)/(pi0+ tmp)\n    }\n    colnames(W) <- colnames(res$others$r)\n    W\n  })\n}\n\n#' Postive-conditional weight computations for wrench estimators.\n#' @param res result structure of \\code{wrench}\n#' @export\ngetCondWeights <- function( res ) {\n  with(res$others, {\n    radj[radj==0] <- NA\n    (1-pi0)/(( pi0 + replicate( nrow(design), exp(s2) ) -1 )*(radj^2))\n  })\n}\n\n#' Log Postive-conditional weight computations for wrench estimators.\n#' @param res result structure of \\code{wrench}\n#' @export\ngetCondLogWeights <- function( res ) {\n  with(res$others, {\n    radj[radj==0] <- NA\n    (1-pi0)/(( pi0 + replicate( nrow(design), exp(s2) ) -1 ))\n  })\n}\n\n#' @export\ngetWeightedMean <- function( mat, w=rep(1, nrow(mat)) ){\n  require(matrixStats)\n  require(limma)\n  if( is.vector(w) ){\n    w <- c(w)\n    res <- colWeightedMeans( mat, w )\n  } else {\n    res <- sapply( seq(ncol(mat)), function(j){\n      yj <- mat[,j]\n      wj <- w[,j]\n      yj <- yj[!is.na(w)]\n      wj <- wj[!is.na(w)]\n      weighted.mean( yj, wj, na.rm=T )\n    } )\n  }\n  return(res)\n}\n\n#' Obtain robust means. .\n#' @param res result structure of \\code{wrench}\n#' @param estim.type estimator type\n#' @export\nestimSummary <- function( res, estim.type=\"s2.w.mean\", ...  ){\n  require(matrixStats)\n\n  if(estim.type==\"s2.w.mean\"){ #weights based on s2\n    with(res$others, colWeightedMeans( radj, 1/s2 ))\n  } else if( estim.type==\"gs.mean\" ){ #this performs well for real-life data\n    with(res$others,{\n      y <- apply( radj, 2, function(x) exp((1/length(x))*sum( log( x[x>0] ) )) )\n      y/exp(mean(log(y)))\n    })\n  } else if(estim.type==\"mean\"){\n    with(res$others,{\n      colMeans(radj)/exp(mean(log(colMeans(radj))))\n    })\n  } else if( estim.type==\"median\" ) {\n    with(res$others,  colMedians(radj)/exp(mean(log(colMedians(radj))))\n    )\n  } else if( estim.type==\"w.marg.median\" ){\n    W <- getMargWeights( res, ... )\n    with(res$others, {\n      sapply( seq(ncol(radj)), function(j){\n        y <- radj[,j]\n        w <- W[,j]\n        y <- y[!is.na(w)]\n        w <- w[!is.na(w)]\n        weighted.median( y, w )\n      } )\n    })\n  } else if (estim.type==\"w.marg.mean\"){\n    W <- getMargWeights( res, ... )\n    with(res$others, {\n      sapply( seq(ncol(radj)), function(j){\n        y <- radj[,j]\n        w <- W[,j]\n        y <- y[!is.na(w)]\n        w <- w[!is.na(w)]\n        weighted.mean( y, w )\n      } )\n    })\n  }else if( estim.type==\"w.cond.median\" ){\n    W <- getCondWeights( res )\n    with(res$others, {\n      sapply( seq(ncol(radj)), function(j){\n        y <- radj[,j]\n        w <- W[,j]\n        y <- y[!is.na(w)]\n        w <- w[!is.na(w)]\n        weighted.median( y, w )\n      } )\n    })\n  } else if( estim.type==\"w.cond.mean\"){\n    W <- getCondWeights( res )\n    with(res$others, {\n      sapply( seq(ncol(radj)), function(j){\n        y <- radj[,j]\n        w <- W[,j]\n        y <- y[!is.na(w)]\n        w <- w[!is.na(w)]\n        weighted.mean( y, w )\n      } )\n    })\n  } else if( estim.type==\"w.cond.log.median\" ){\n    W <- getCondLogWeights( res )\n    with(res$others, {\n      sapply( seq(ncol(radj)), function(j){\n        y <- log(radj[,j])\n        y[!is.finite(y)] <- NA\n        w <- W[,j]\n        y <- y[!is.na(w)]\n        w <- w[!is.na(w)]\n        exp(weighted.median( y, w, na.rm=T ))\n      } )\n    })\n  } else if( estim.type==\"w.cond.log.mean\"){\n    W <- getCondLogWeights( res )\n    with(res$others, {\n      sapply( seq(ncol(radj)), function(j){\n        y <- log(radj[,j])\n        y[!is.finite(y)] <- NA\n        w <- W[,j]\n        y <- y[!is.na(w)]\n        w <- w[!is.na(w)]\n        exp(weighted.mean( y, w, na.rm=T ))\n      } )\n    })\n  } else if( estim.type==\"hurdle.w.mean\"  ){\n    #hurdle weights applied to regularized ratios\n    W <- 1/(1-res$others$pi0) #hurdle weights\n    with(res$others, {\n      sapply( seq(ncol(r)), function(j){\n        y <- r[,j]\n        w <- W[,j]\n        weighted.mean( r[,j], W[,j])\n      } )\n    })\n  }\n}\n\n#' @export\ngetReference <- function( mat, ref.est=\"sw.means\", ... ){\n  require(matrixStats)\n  tots <- colSums(mat)\n  if(ref.est==\"logistic\"){\n    qref <- 1-plogis(\n      apply( mat, 1, function(x){\n        glm( cbind(tots-x, x)~1, family=binomial() )$coefficients\n      }  )\n    )\n  } else if(ref.est == \"sw.means\"){ #sample-wise means\n    qmat <- sweep(mat, 2, colSums(mat), \"/\")\n    qref <- rowMeans(qmat)\n  } else {\n    stop(\"Unknown reference type.\")\n  }\n  qref\n}\n\n#' @title Normalization for sparse, under-sampled count data.\n#'\n#' @description Obtain normalization factors for sparse, under-sampled count data that often arise with\n#' metagenomic count data.\n#'\n#' @param mat count matrix; rows are features and columns are samples\n#' @param condition a vector with group information on the samples\n#' @param etype weighting strategy with the following options:\n#'        \\itemize{\n#'        \\item{ hurdle.w.mean, the W1 estimator in manuscript.}\n#'        \\item{ w.marg.mean, the W2 estimator in manuscript. These are appropriately computed depending on\n#'                             whether \\code{z.adj}=T (see below)\n#'        }\n#'        \\item{s2.w.mean, weight by inverse of feature-variances of logged count data. }\n#'        }\n#' @param ebcf TRUE if empirical bayes regularization of ratios needs to be performed. Default recommended.\n#' @param z.adj TRUE if the feature-wise ratios need to be adjusted\n#'              by hurdle probabilities (arises when taking marginal expectation). Default recommended.\n#' @param phi.adj TRUE if estimates need to be adjusted for variance terms\n#'                (arises when considering positive-part expectations). Default recommended.\n#' @return a \\code{list} with components:\n#'         \\itemize{\n#'         \\item{ \\code{nf}, \\emph{normalization factors} for samples passed.\n#'                Samples with zero total counts are removed from output. }\n#'         \\item{ \\code{ccf}, \\emph{compositional correction factors}.\n#'                Samples with zero total counts are removed from output.\n#'           }\n#'         \\item{ \\code{others},  a \\code{list} with results from intermediate computations. }\n#'         \\itemize{\n#'         \\item{ \\code{qref},  reference chosen. }\n#'         \\item{ \\code{design},  design matrix used for computation of positive-part parameters. }\n#'         \\item{ \\code{s2},   feature-wise variances of logged count data. }\n#'         \\item{ \\code{r},  (regularized) ratios of feature-wise proportions. }\n#'         \\item{ \\code{radj},  adjustments made to the regularized ratios based\n#'                              on z.adj and phi.adj settings.}\n#'         }\n#'         }\n#' @examples\n#' #Obtain counts matrix and some group information\n#' require(metagenomeSeq)\n#' data(mouseData)\n#' cntsMatrix <- MRcounts(mouseData)\n#' group <- pData(mouseData)$diet\n\n#' #Running wrench with defaults\n#' W <- wrench( cntsMatrix, condition=group  )\n#' compositionalFactors <- W$ccf\n#' normalizationFactors <- W$nf\n#'\n#'#Introducing the above normalization factors for the most\n#'# commonly used tools is shown below.\n#'\n\n#' #If using edgeR, we must pass in the compositional factors\n#'require(edgeR)\n#'edgerobj <- DGEList( counts=cntsMatrix,\n#'                      group = as.matrix(group),\n#'                      norm.factors=compositionalFactors )\n#'\n\n#' #If using DESeq/DESeq2\n#'require(DESeq2)\n#'deseq.obj <- DESeqDataSetFromMatrix(countData = cntsMatrix,\n#'                                    colData = group,\n#'                                    design=as.formula(paste(\"~\",diet))\n#')\n#'sizeFactors( deseq.obj  ) <- normFactors\n#'\n#' #If using metagenomeSeq\n#' normalizedObject <- mouseData\n#' pData(normalizedObject@expSummary$expSummary)$normFactors <- normFactors\n#'\n\n#' @author M. Senthil Kumar\n#' @export\nwrench <- function( mat, condition, etype=\"w.marg.mean\",\n                    ebcf=T, z.adj=F, phi.adj=T, ... ){\n\n  require(matrixStats)\n\n  #trim\n  mat <- mat[rowSums(mat)>0,]\n  nzcols <- colSums(mat)>0\n  mat <- mat[,nzcols]\n  condition <- condition[nzcols]\n\n\n  #feature-wise parameters: hurdle, variance, reference and raw ratios\n  n <- ncol(mat)\n  tots <- colSums(mat)\n  compute.pi0 <- !((etype %in% c(\"mean\", \"median\", \"s2.w.mean\")) & !z.adj )\n  if(compute.pi0){\n    pi0 <- getHurdle( mat, ... )$pi0\n  }\n  group <- as.character(condition)\n  if(length(unique(group)) == 1){\n    design <- model.matrix(mat[1,]~1)\n  } else {\n    design <- model.matrix(~-1+group)\n  }\n  s2 <- gets2(mat,design,...)\n\n  #refernece\n  qref <- getReference( mat, ... )\n\n  #sample-wise ratios\n  qmat <- sweep(mat, 2, colSums(mat), \"/\")\n  r <- qmat/qref\n\n  if(ebcf){\n    #group-wise ratios\n    Yg <- sapply( unique(group), function(g){\n      if(sum(group==g)>1){\n        rowSums(mat[,group==g])\n      } else {\n        mat[,group==g]\n      }\n    }  )\n    qg <- sweep(Yg, 2, colSums(Yg), \"/\") #weighted estimator\n    rg <- qg/qref\n    lrg <- log(rg)\n    lrg[!is.finite(lrg)] <- NA\n    s2thetag <- colVars(lrg, na.rm=T)\n    s2thetag_rep <- design %*% s2thetag\n\n    thetag <- colMeans(rg)\n    thetag_rep <- c(design %*% thetag)\n\n    #regularized estimation of positive means.\n    r <- sweep(r, 2, thetag_rep, \"/\")\n    thetagj <- exp( sapply(seq(n), function(j){\n      x <- log(r[,j])\n      x[!is.finite(x)] <- NA\n      weighted.mean( x, w=1/(s2+s2thetag_rep[j]), na.rm=T )\n    }))\n\n    p <- nrow(r)\n    thetagi <- t( sapply(seq(p), function(i){\n      exp(\n        (s2thetag/(s2[i]+s2thetag))*( log(r[i,]) - log(thetagj) )\n      )\n    }) )\n\n    r <- sweep( thetagi, 2, thetagj*thetag_rep, \"*\")\n  }\n\n  #adjustments for marginal, and truncated means.\n  phi2 <- exp(s2)\n  radj <- r\n  if(z.adj){\n    radj <- radj/(1-pi0)\n  }\n  if(phi.adj){\n    radj <- sweep( radj, 1, sqrt(phi2), \"/\" )\n  }\n\n\n  #return result structure\n  res <- list()\n  res$others <- list()\n  if(ebcf){\n    res$others <- list( \"rg\" = rg,\n                        \"thetag\" = thetag,\n                        \"thetagi\" = thetagi,\n                        \"s2thetag\" = s2thetag\n    )\n  }\n  res$others <- c(\n    res$others,\n    list(\n      \"qref\"=qref,\n      \"design\" = design,\n      \"s2\" = s2,\n      \"r\" = r,\n      \"radj\" = radj)\n  )\n  if(compute.pi0){\n    res$others <- c(res$others, list(\"pi0\"=pi0))\n  }\n\n  res$ccf <- estimSummary( res, estim.type = etype, z.adj=z.adj, ... )\n  res$ccf <- with(res, ccf/exp(mean(log(ccf))))\n  tjs <- colSums(mat)/exp(mean(log(colSums(mat))))\n  res$nf <- res$ccf * tjs\n\n\n  res\n}\n",
    "created" : 1487816953343.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3702338340",
    "id" : "12D97211",
    "lastKnownWriteTime" : 1487816872,
    "last_content_update" : 1487816872,
    "path" : "~/Documents/research/metagenomics/RPackages/Wrench/R/wrenchSource.R",
    "project_path" : "R/wrenchSource.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}